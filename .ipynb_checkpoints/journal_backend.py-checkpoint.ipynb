{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Journal entry: \"I never see my dad often because he’s always at work or I might see him in the morning but we’d wouldn’t talk, but my dad never supported me in what I want to do or what I did, he would always say “Ok, do better” and I can’t even have a proper conversation with him with yelling or having an argument with him, and he would yell at me for no reason, I remember once I went to my cousin’s house and I saw my uncle having a tray of homemade breakfast for my cousin and even brought it to her and told her good morning and gave her a hug, and she’s like 18 and like when I saw that it just kinda made me really sad inside that my dad would never do that for me\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "659"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#prompt for user to input a journal entry\n",
    "journal = input(\"Journal your feelings and vent about a time you were stressed\")\n",
    "print(\"Journal entry: \" + journal)\n",
    "\n",
    "#creating txt file for the user input\n",
    "y=open(r'C:\\Users\\gurmo\\OneDrive\\Desktop\\Sait 2022\\nathacks 2022\\Doc1.txt', 'w')\n",
    "y.write(journal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dad', 3), ('morning', 2), ('cousin', 2), ('work', 1), ('conversation', 1), ('argument', 1), ('reason', 1), ('house', 1), ('uncle', 1), ('tray', 1), ('breakfast', 1), ('hug', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Load Our Packages\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from collections import Counter\n",
    " \n",
    "from tables import split_type\n",
    "#nlp = spacy.load('en')\n",
    " \n",
    "# Load spacy pipeline\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    " \n",
    "# Load spacy pipeline\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    " \n",
    "# redditcontent = nlp(open('MigraineText.txt', 'r', encoding='utf-8'))\n",
    "# redditcontentstring = nlp(redditcontent.read())\n",
    "redditcontentstring = nlp(open('Doc1.txt', 'r', encoding='cp1252').read())\n",
    "# docx\n",
    "#print(redditcontentstring)\n",
    " \n",
    "nouns = [ token.text for token in redditcontentstring if token.is_stop != True and token.is_punct !=True and token.pos_ == 'NOUN']\n",
    "# nouns\n",
    " \n",
    "word_freq = Counter(nouns)\n",
    "common_nouns = word_freq.most_common(100)\n",
    "print(common_nouns)\n",
    " \n",
    "# Export to CSV\n",
    "#df = pd.DataFrame(common_nouns)\n",
    "# df.columns = [Input,'Sentence', 'Aspect', 'Descriptive Term', 'Polarity', 'Subjectivity']\n",
    "#df.columns = [\"WordPosts\",\"WordPostCounts\"]\n",
    "#df.to_csv('kneepainCount.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" PUNCT punct\n",
      "I PRON nsubj\n",
      "never ADV neg\n",
      "see VERB ccomp\n",
      "my PRON poss\n",
      "dad NOUN dobj\n",
      "often ADV advmod\n",
      "because SCONJ mark\n",
      "he PRON nsubj\n",
      "’s VERB advcl\n",
      "always ADV advmod\n",
      "at ADP prep\n",
      "work NOUN pobj\n",
      "or CCONJ cc\n",
      "I PRON nsubj\n",
      "might AUX aux\n",
      "see VERB conj\n",
      "him PRON dobj\n",
      "in ADP prep\n",
      "the DET det\n",
      "morning NOUN pobj\n",
      "but CCONJ cc\n",
      "we PRON nsubj\n",
      "’d NOUN appos\n",
      "would AUX aux\n",
      "n’t PART neg\n",
      "talk VERB conj\n",
      ", PUNCT punct\n",
      "but CCONJ cc\n",
      "my PRON poss\n",
      "dad NOUN nsubj\n",
      "never ADV neg\n",
      "supported VERB conj\n",
      "me PRON dobj\n",
      "in ADP prep\n",
      "what PRON dobj\n",
      "I PRON nsubj\n",
      "want VERB pcomp\n",
      "to PART aux\n",
      "do VERB xcomp\n",
      "or CCONJ cc\n",
      "what PRON dobj\n",
      "I PRON nsubj\n",
      "did VERB conj\n",
      ", PUNCT punct\n",
      "he PRON nsubj\n",
      "would AUX aux\n",
      "always ADV advmod\n",
      "say VERB ccomp\n",
      "“ PUNCT punct\n",
      "Ok INTJ intj\n",
      ", PUNCT punct\n",
      "do VERB xcomp\n",
      "better ADJ advmod\n",
      "” PUNCT punct\n",
      "and CCONJ cc\n",
      "I PRON nsubj\n",
      "ca AUX aux\n",
      "n’t PART neg\n",
      "even ADV advmod\n",
      "have VERB conj\n",
      "a DET det\n",
      "proper ADJ amod\n",
      "conversation NOUN dobj\n",
      "with ADP prep\n",
      "him PRON pobj\n",
      "with ADP prep\n",
      "yelling VERB pcomp\n",
      "or CCONJ cc\n",
      "having VERB conj\n",
      "an DET det\n",
      "argument NOUN dobj\n",
      "with ADP prep\n",
      "him PRON pobj\n",
      ", PUNCT punct\n",
      "and CCONJ cc\n",
      "he PRON nsubj\n",
      "would AUX aux\n",
      "yell VERB conj\n",
      "at ADP prep\n",
      "me PRON pobj\n",
      "for ADP prep\n",
      "no DET det\n",
      "reason NOUN pobj\n",
      ", PUNCT punct\n",
      "I PRON nsubj\n",
      "remember VERB ROOT\n",
      "once SCONJ mark\n",
      "I PRON nsubj\n",
      "went VERB ccomp\n",
      "to ADP prep\n",
      "my PRON poss\n",
      "cousin NOUN compound\n",
      "’s PART compound\n",
      "house NOUN pobj\n",
      "and CCONJ cc\n",
      "I PRON nsubj\n",
      "saw VERB conj\n",
      "my PRON poss\n",
      "uncle NOUN nsubj\n",
      "having VERB ccomp\n",
      "a DET det\n",
      "tray NOUN dobj\n",
      "of ADP prep\n",
      "homemade ADJ amod\n",
      "breakfast NOUN pobj\n",
      "for ADP prep\n",
      "my PRON poss\n",
      "cousin NOUN pobj\n",
      "and CCONJ cc\n",
      "even ADV advmod\n",
      "brought VERB conj\n",
      "it PRON dobj\n",
      "to ADP prep\n",
      "her PRON pobj\n",
      "and CCONJ cc\n",
      "told VERB conj\n",
      "her PRON poss\n",
      "good ADJ amod\n",
      "morning NOUN dobj\n",
      "and CCONJ cc\n",
      "gave VERB conj\n",
      "her PRON dative\n",
      "a DET det\n",
      "hug NOUN dobj\n",
      ", PUNCT punct\n",
      "and CCONJ cc\n",
      "she PRON nsubj\n",
      "’s VERB conj\n",
      "like INTJ intj\n",
      "18 NUM npadvmod\n",
      "and CCONJ cc\n",
      "like INTJ intj\n",
      "when SCONJ advmod\n",
      "I PRON nsubj\n",
      "saw VERB advcl\n",
      "that SCONJ mark\n",
      "it PRON nsubj\n",
      "just ADV advmod\n",
      "kinda ADV advmod\n",
      "made VERB ccomp\n",
      "me PRON nsubj\n",
      "really ADV advmod\n",
      "sad ADJ ccomp\n",
      "inside ADP prep\n",
      "that SCONJ mark\n",
      "my PRON poss\n",
      "dad NOUN nsubj\n",
      "would AUX aux\n",
      "never ADV neg\n",
      "do VERB ccomp\n",
      "that PRON dobj\n",
      "for ADP prep\n",
      "me PRON pobj\n",
      "\" PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "redditcontentstring = nlp(open('Doc1.txt', 'r', encoding='cp1252').read())\n",
    "for token in redditcontentstring:\n",
    "    print(token.text, token.pos_, token.dep_)\n",
    "\n",
    "#code for entities\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "redditcontentstring = nlp(open('Doc1.txt', 'r', encoding='cp1252').read())\n",
    "\n",
    "for ent in redditcontentstring.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"I never see my dad often because he’s always at work or I might see him in the morning but we’d wouldn’t talk, but my dad never supported me in what I want to do or what I did, he would always say “Ok, do better” and I can’t even have a proper conversation with him with yelling or having an argument with him, and he would yell at me for no reason, I remember once I went to my cousin’s house and I saw my uncle having a tray of homemade breakfast for my cousin and even brought it to her and told her good morning and gave her a hug, and she’s like 18 and like when I saw that it just kinda made me really sad inside that my dad would never do that for me\"\n"
     ]
    }
   ],
   "source": [
    "# Load Our Packages\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from collections import Counter\n",
    " \n",
    "from tables import split_type\n",
    "#nlp = spacy.load('en')\n",
    " \n",
    "# Load spacy pipeline\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    " \n",
    "# Load spacy pipeline\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    " \n",
    "# redditcontent = nlp(open('MigraineText.txt', 'r', encoding='utf-8'))\n",
    "# redditcontentstring = nlp(redditcontent.read())\n",
    "redditcontentstring = nlp(open('Doc1.txt', 'r', encoding='cp1252').read())\n",
    "\n",
    "tokens = redditcontentstring\n",
    "\n",
    "def check_verb(token):\n",
    "    \"\"\"Check verb type given spacy token\"\"\"\n",
    "    if token.pos_ == 'VERB':\n",
    "        indirect_object = False\n",
    "        direct_object = False\n",
    "        for item in token.children:\n",
    "            if(item.dep_ == \"iobj\" or item.dep_ == \"pobj\"):\n",
    "                indirect_object = True\n",
    "            if (item.dep_ == \"dobj\" or item.dep_ == \"dative\"):\n",
    "                direct_object = True\n",
    "        if indirect_object and direct_object:\n",
    "            return 'DITRANVERB'\n",
    "        elif direct_object and not indirect_object:\n",
    "            return 'TRANVERB'\n",
    "        elif not direct_object and not indirect_object:\n",
    "            return 'INTRANVERB'\n",
    "        else:\n",
    "            return 'VERB'\n",
    "    else:\n",
    "        return token.pos_\n",
    "\n",
    "print(tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "fad1b179a91d41a0b14d3d47b729614d24c4bbfd77e9848bc70857acbaefee90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
